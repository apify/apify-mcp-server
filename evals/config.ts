/**
 * Configuration for Apify MCP Server evaluations.
 */

import { readFileSync } from 'node:fs';
import { dirname, join } from 'node:path';
import { fileURLToPath } from 'node:url';

// Read version from test-cases.json
function getTestCasesVersion(): string {
    const currentFilename = fileURLToPath(import.meta.url);
    const currentDirname = dirname(currentFilename);
    const testCasesPath = join(currentDirname, 'test-cases.json');
    const testCasesContent = readFileSync(testCasesPath, 'utf-8');
    const testCases = JSON.parse(testCasesContent);
    return testCases.version;
}

// Evaluator names
export const EVALUATOR_NAMES = {
    TOOLS_EXACT_MATCH: 'tool-exact-match',
    TOOL_SELECTION_LLM: 'tool-selection-llm',
} as const;

export type EvaluatorName = typeof EVALUATOR_NAMES[keyof typeof EVALUATOR_NAMES];

// Models to evaluate
export const MODELS_TO_EVALUATE = [
    'openai/gpt-4o-mini',
    'anthropic/claude-3.5-haiku',
    'google/gemini-2.5-flash',
];

export const TOOL_SELECTION_EVAL_MODEL = 'openai/gpt-4o-mini';

export const PASS_THRESHOLD = 0.8;

export const DATASET_NAME = `mcp_tool_calling_ground_truth_v${getTestCasesVersion()}`;

// System prompt
export const SYSTEM_PROMPT = 'You are a helpful assistant';

export const TOOL_CALLING_BASE_TEMPLATE = `
You are an evaluation assistant evaluating questions and tool calls to
determine whether the tool called would answer the question. The tool
calls have been generated by a separate agent, and chosen from the list of
tools provided below. It is your job to decide whether that agent chose
the right tool to call.

    [BEGIN DATA]
    ************
    [Context]: {input}
    ************
    [LLM response]: {llm_response}
    [END DATA]

Your response must be single word, either "correct" or "incorrect",
and should not contain any text or characters aside from that word.
"incorrect" means that the chosen tool would not answer the question,
the tool includes information that is not presented in the question,
or that the tool signature includes parameter values that don't match
the formats specified in the tool signatures below.

"correct" means the correct tool call was chosen, the correct parameters
were extracted from the question, the tool call generated is runnable and correct,
and that no outside information not present in the question was used
in the generated question.

[Reference instructions]: {reference}

[Tool Definitions]: {tool_definitions}
`;
export function getRequiredEnvVars(): Record<string, string | undefined> {
    return {
        PHOENIX_BASE_URL: process.env.PHOENIX_BASE_URL,
        PHOENIX_API_KEY: process.env.PHOENIX_API_KEY,
        OPENROUTER_API_KEY: process.env.OPENROUTER_API_KEY,
        OPENROUTER_BASE_URL: process.env.OPENROUTER_BASE_URL,
    };
}

// Removes newlines and trims whitespace. Useful for Authorization header values
// because CI secrets sometimes include trailing newlines or quotes.
export function sanitizeHeaderValue(value?: string): string | undefined {
    if (value == null) return value;
    return value.replace(/[\r\n]/g, '').trim().replace(/^"|"$/g, '');
}

export function validateEnvVars(): boolean {
    const envVars = getRequiredEnvVars();
    const missing = Object.entries(envVars)
        .filter(([, value]) => !value)
        .map(([key]) => key);

    if (missing.length > 0) {
        // eslint-disable-next-line no-console
        console.error(`Missing required environment variables: ${missing.join(', ')}`);
        return false;
    }

    return true;
}
